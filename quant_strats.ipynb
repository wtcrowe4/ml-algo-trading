{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs all the necessary packages for the project\n",
    "# %pip install pandas pandas-ta numpy matplotlib statsmodels pandas_datareader datetime yfinance scikit-learn PyPortfolioOpt\n",
    "# %pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all the necessary packages for the project and fixes ssl error\n",
    "import ssl\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[***************       31%%                      ]  154 of 503 completed"
     ]
    }
   ],
   "source": [
    "# Get SP500 data    \n",
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.', '-')\n",
    "symbols_list = sp500['Symbol'].unique().tolist()\n",
    "\n",
    "end_date = dt.datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (pd.to_datetime(end_date) - pd.DateOffset(years=10)).strftime('%Y-%m-%d')\n",
    "\n",
    "df = yf.download(tickers=symbols_list, start=start_date, end=end_date).stack()\n",
    "\n",
    "df.index.names = ['Date', 'Symbol']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features and technical indicators\n",
    "# Garman-Klass Volatility, RSI, Bollinger Bands, ATR, MACD, Dollar Volume,\n",
    "# All but RSI are normalized by subtracting the mean and dividing by the standard deviation\n",
    "\n",
    "df['Garman-Klass'] = ((np.log(df['High'])-np.log(df['Low']))**2)/2-(2*np.log(2)-1)*((np.log(df['Adj Close'])-np.log(df['Open']))**2)  \n",
    "\n",
    "df['RSI'] = df.groupby(level=1)['Adj Close'].transform(lambda x: ta.rsi(close=x, length=20))\n",
    "\n",
    "df['BB-Low'] = df.groupby(level=1)['Adj Close'].transform(lambda x: ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "df['BB-Mid'] = df.groupby(level=1)['Adj Close'].transform(lambda x: ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "df['BB-High'] = df.groupby(level=1)['Adj Close'].transform(lambda x: ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "def compute_atr(data):\n",
    "    atr = ta.atr(high=data['High'],\n",
    "                        low=data['Low'],\n",
    "                        close=data['Close'],\n",
    "                        length=14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "df['ATR'] = df.groupby(level=1, group_keys=False).apply(compute_atr)\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = ta.macd(close=close, length=20).iloc[:,0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "df['MACD'] = df.groupby(level=1, group_keys=False)['Adj Close'].apply(compute_macd)\n",
    "\n",
    "df['Dollar Volume'] = (df['Adj Close']*df['Volume'])/1e6\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to monthly data and filter top 150 most liquid stocks for each month\n",
    "\n",
    "tech_cols = [c for c in df.columns.unique(0) if c not in ['Dollar Volume', 'Volume', 'Open',\n",
    "                                                          'High', 'Low', 'Close']]\n",
    "\n",
    "tech_data = (pd.concat([df.unstack('Symbol')['Dollar Volume'].resample('M').mean().stack('Symbol').to_frame('Dollar Volume'),\n",
    "                   df.unstack()[tech_cols].resample('M').last().stack('Symbol')],\n",
    "                  axis=1)).dropna()\n",
    "\n",
    "# Calculate 5-year rolling average of Dollar Volume\n",
    "tech_data['Dollar Volume'] = (tech_data.loc[:, 'Dollar Volume'].unstack('Symbol').rolling(5*12, min_periods=12).mean().stack())\n",
    "\n",
    "tech_data['DV Rank'] = (tech_data.groupby('Date')['Dollar Volume'].rank(ascending=False))\n",
    "\n",
    "# Filter top 150 most liquid stocks for each month and put in new dataframe\n",
    "#tech_data = tech_data[tech_data['DV Rank']<150].drop(['Dollar Volume', 'DV Rank'], axis=1)\n",
    "top_150 = tech_data[tech_data['DV Rank'] < 150]\n",
    "\n",
    "top_150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly returns for different time horizons on the top 150 most liquid stocks\n",
    "def calculate_returns(df):\n",
    "    outlier_cutoff = 0.005\n",
    "    lags = [1, 2, 3, 6, 9, 12]\n",
    "    for lag in lags:\n",
    "        df[f'{lag}m Return'] = (df['Adj Close']\n",
    "                              .pct_change(lag)\n",
    "                              .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                     upper=x.quantile(1-outlier_cutoff)))\n",
    "                              .add(1)\n",
    "                              .pow(1/lag)\n",
    "                              .sub(1))\n",
    "    return df\n",
    "\n",
    "returns = top_150.groupby(level=1, group_keys=False).apply(calculate_returns).dropna()\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Famaâ€”French data to estimate the exposure of assets to common risk factors using linear regression.\n",
    "\n",
    "factor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3', 'famafrench', start=start_date, end=end_date)[0].drop('RF', axis=1)\n",
    "factor_data.index = factor_data.index.to_timestamp()\n",
    "factor_data.index.name = 'Date'\n",
    "factor_data = factor_data.resample('M').last().div(100)\n",
    "factor_data = factor_data.join(returns['1m Return']).sort_index()\n",
    "\n",
    "\n",
    "# Filter out stocks with less than 10 months of data.\n",
    "observations = factor_data.groupby(level=1).size()\n",
    "valid_stocks = observations[observations >= 10]\n",
    "factor_data = factor_data[factor_data.index.get_level_values('Symbol').isin(valid_stocks.index)]\n",
    "\n",
    "factor_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rolling Factor Betas\n",
    "\n",
    "betas = (factor_data.groupby(level=1,\n",
    "                            group_keys=False)\n",
    "         .apply(lambda x: RollingOLS(endog=x['1m Return'], \n",
    "                                     exog=sm.add_constant(x.drop('1m Return', axis=1)),\n",
    "                                     window=min(24, x.shape[0]),\n",
    "                                     min_nobs=len(x.columns)+1)\n",
    "         .fit(params_only=True)\n",
    "         .params\n",
    "         .drop('const', axis=1)))\n",
    "\n",
    "#betas \n",
    "\n",
    "# Join betas to returns dataframe\n",
    "factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "data = (returns.join(betas.groupby('Symbol').shift()))\n",
    "data.loc[:, factors] = data.groupby('Symbol', group_keys=False)[factors].apply(lambda x: x.fillna(x.mean()))\n",
    "#data = data.drop(['Adj Close', 'Dollar Volume', 'DV Rank', axis=1)\n",
    "data = data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering for each month\n",
    "from sklearn.cluster import KMeans\n",
    "# N Clusters = 4\n",
    "# Define initial centroids\n",
    "\n",
    "target_rsi_values = [30, 45, 55, 70]\n",
    "initial_centroids = np.zeros((len(target_rsi_values), 22))\n",
    "initial_centroids[:, 6] = target_rsi_values\n",
    "\n",
    "\n",
    "def get_clusters(df):\n",
    "    df['Cluster'] = KMeans(n_clusters=4,\n",
    "                           #random_state=0,\n",
    "                           init=initial_centroids).fit(df).labels_\n",
    "    return df\n",
    "\n",
    "data = data.dropna().groupby('Date', group_keys=False).apply(get_clusters)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Clusters\n",
    "# def plot_clusters(df):\n",
    "#     cluster0 = df[df['Cluster']==0]\n",
    "#     cluster1 = df[df['Cluster']==1]\n",
    "#     cluster2 = df[df['Cluster']==2]\n",
    "#     cluster3 = df[df['Cluster']==3]\n",
    "\n",
    "#     plt.scatter(cluster0['ATR'], cluster0['RSI'], color='red', label='Cluster 0')\n",
    "#     plt.scatter(cluster1['ATR'], cluster1['RSI'], color='green', label='Cluster 1')\n",
    "#     plt.scatter(cluster2['ATR'], cluster2['RSI'], color='blue', label='Cluster 2')\n",
    "#     plt.scatter(cluster3['ATR'], cluster3['RSI'], color='yellow', label='Cluster 3')\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     return \n",
    "\n",
    "\n",
    "def plot_clusters(df):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, cluster in df.groupby('Cluster'):\n",
    "        cluster.plot.scatter(x='ATR', y='RSI', ax=ax, label=f'Cluster {i}', color=f'C{i}')\n",
    "    return\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "for i in data.index.get_level_values('Date').unique().tolist():\n",
    "    cluster = data.xs(i, level='Date')\n",
    "    plt.title(f'Date {i.strftime(\"%Y-%m\")}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plot_clusters(cluster)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each month select assets based on the cluster and form a portfolio based on Efficient Frontier max sharpe ratio optimization\n",
    "filtered_df = data[data['Cluster']==3].copy()\n",
    "\n",
    "filtered_df = filtered_df.reset_index(level=1)\n",
    "\n",
    "filtered_df.index = filtered_df.index+pd.DateOffset(1)\n",
    "\n",
    "filtered_df = filtered_df.reset_index().set_index(['date', 'ticker'])\n",
    "\n",
    "dates = filtered_df.index.get_level_values('date').unique().tolist()\n",
    "\n",
    "fixed_dates = {}\n",
    "\n",
    "for d in dates:\n",
    "    \n",
    "    fixed_dates[d.strftime('%Y-%m-%d')] = filtered_df.xs(d, level=0).index.tolist()\n",
    "    \n",
    "fixed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define portfolio optimization function\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
